import cv2
import numpy as np
import pyautogui
import time
import base64
from io import BytesIO
from PIL import ImageGrab
from openai import OpenAI

# ====== é…ç½®é¡¹ ======
API_KEY = "sk-xxx"  # æ›¿æ¢ä¸ºä½ çš„ DashScope Key ##æ²¡æœ‰çš„è¯å°±å»qwenå®˜ç½‘è·å–
ICON_DIR = r"D:\tubiao"# æ›¿æ¢ä¸ºä½ çš„ å­˜æ”¾tubiaoæ–‡ä»¶å¤¹çš„ä½ç½®
THRESHOLD = 0.80  # æ¨¡æ¿åŒ¹é…ç½®ä¿¡åº¦

client = OpenAI(
    api_key=API_KEY,
    base_url="https://dashscope.aliyuncs.com/compatible-mode/v1"
)

# å®¡æ ¸æç¤º
AUDIT_PROMPT = (
    "è¿™æ˜¯é”€å”®å‡­è¯æˆªå›¾ï¼Œè¯·åˆ¤æ–­æ˜¯å¦åˆæ ¼ï¼Œåˆæ ¼è¿”å›1ï¼Œä¸åˆæ ¼è¿”å›0ï¼š\n"
    "å¿…é¡»åŒ…å«å•†æˆ·åã€æ—¥æœŸã€é‡‘é¢ã€‚\n"
    "åªè¦çœ‹åˆ°åº—å­—å°±è¯´æ˜åŒ…å«å•†æˆ·åï¼Œå•†æˆ·åè¿™éƒ¨åˆ†å°±åˆæ ¼äº†\n"
    "åªè¦çœ‹åˆ°æ—¥æœŸè¿™ä¸¤ä¸ªå­—åˆ™æ—¥æœŸå°±åˆæ ¼äº†\n"
    "ç¼ºé¡¹åˆ™ä¸ºä¸åˆæ ¼ã€‚\n"
    "ä»…è¿”å›ï¼š1 æˆ– 0ã€‚"
)

# ====== å·¥å…·å‡½æ•° ======

def screenshot_to_dataurl():
    img = ImageGrab.grab()
    buf = BytesIO()
    img.save(buf, format='PNG')
    b64 = base64.b64encode(buf.getvalue()).decode()
    return f"data:image/png;base64,{b64}"

def gpt_judge_image(image_dataurl):
    messages = [{
        "role": "user",
        "content": [
            {"type": "text", "text": AUDIT_PROMPT},
            {"type": "image_url", "image_url": {"url": image_dataurl}}
        ]
    }]
    try:
        response = client.chat.completions.create(
            model="qwen-vl-plus",
            messages=messages
        )
        result = response.choices[0].message.content.strip()
        print(f"ğŸ§  GPTåˆ¤æ–­ç»“æœï¼š{result}")
        return result
    except Exception as e:
        print("âŒ GPTå‡ºé”™ï¼š", e)
        return None

def match_and_click(img_name):
    full_path = f"{ICON_DIR}\\{img_name}"
    template = cv2.imread(full_path)
    if template is None:
        print(f"âŒ æ— æ³•è¯»å–å›¾æ ‡ï¼š{full_path}")
        return False

    screenshot = pyautogui.screenshot()
    screenshot = cv2.cvtColor(np.array(screenshot), cv2.COLOR_RGB2BGR)
    result = cv2.matchTemplate(screenshot, template, cv2.TM_CCOEFF_NORMED)
    _, max_val, _, max_loc = cv2.minMaxLoc(result)

    if max_val >= THRESHOLD:
        h, w = template.shape[:2]
        center = (max_loc[0] + w//2, max_loc[1] + h//2)
        pyautogui.click(center)
        print(f"âœ… ç‚¹å‡» {img_name} â†’ {center}ï¼Œç½®ä¿¡åº¦ï¼š{max_val:.2f}")
        return True
    else:
        print(f"âš ï¸ åŒ¹é…å¤±è´¥ {img_name}ï¼Œç½®ä¿¡åº¦ï¼š{max_val:.2f}")
        return False

# ====== ä¸»æµç¨‹ ======

def audit_once():
    print("\nğŸ” æ–°ä¸€è½®å®¡æ ¸å¼€å§‹")

    # Step 1ï¼šç‚¹å‡»â€œæŸ¥çœ‹â€
    if not match_and_click("chakan.png"):
        print("â¡ï¸ æœªæ‰¾åˆ°æŸ¥çœ‹ï¼Œè·³è¿‡æœ¬è½®")
        return

    time.sleep(2)

    # Step 2ï¼šæˆªå›¾å¹¶æäº¤GPTå®¡æ ¸
    data_url = screenshot_to_dataurl()
    result = gpt_judge_image(data_url)

    time.sleep(0.8)
    match_and_click("guanbi.png")

    time.sleep(0.8)
    if "1" in result:
        match_and_click("tongguo.png")
    elif "0" in result:
        match_and_click("bohui.png")
    else:
        print("â“ æ— æ•ˆå®¡æ ¸ç»“æœï¼Œè·³è¿‡æœ¬è½®")

# ====== ä¸»ç¨‹åºå…¥å£ ======

if __name__ == "__main__":
    print("ğŸš€ è‡ªåŠ¨å®¡æ ¸ç³»ç»Ÿå¯åŠ¨")
    try:
        while True:
            audit_once()
            time.sleep(1.5)
    except KeyboardInterrupt:
        print("â›” æ‰‹åŠ¨ä¸­æ­¢")
